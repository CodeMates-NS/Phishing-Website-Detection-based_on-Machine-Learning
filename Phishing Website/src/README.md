# ğŸ” Machine Learning-Based Phishing Website Detection

A web application built with **Flask** and **Machine Learning** that detects **phishing websites** based on 30 extracted URL features such as SSL state, domain age, subdomain structure, and request patterns.  
The system predicts whether a given website is **legitimate** or **phishing** and provides human-readable reasoning behind each prediction.

---

## ğŸš€ Project Overview
- Machine-learning-based phishing detection  
- Safe URL-only analysis  
- Random Forest backend  
- Modern cyber-themed UI  

---

## âœ¨ Key Features
- âœ… URL-based phishing detection  
- âœ… Explainable predictions  
- âœ… 30-feature extraction system  
- âœ… Cyber-themed responsive UI  
- âœ… Auto URL normalization  
- âœ… Invalid input handling  
- âœ… Calibrated confidence score  

---

## ğŸ›  Additional Enhancements
### ğŸ”— URL Normalization  
- Converts partial URLs into correct format  

### ğŸ›‘ Invalid Input Filtering  
- Prevents random non-URL text  

### ğŸ“Š Confidence Calibration  
- Displays realistic model confidence  

### ğŸ¨ UI Upgrade  
- Dim neon glow and centered layout  

---

## ğŸ§© System Architecture

```
User Input (URL)
        â†“
Feature Extraction (30 handcrafted URL-based features)
        â†“
Trained ML Model (Random Forest Classifier)
        â†“
Prediction (Phishing âš ï¸ or Legitimate âœ…)
        â†“
Explainable Reason Display (Top 3â€“4 reasons)
```

---

## ğŸ“ Folder Structure

```
Phishing Website/
â”‚
â”œâ”€â”€ images/                         # Screenshots, model analysis visuals
â”‚   â”œâ”€â”€ Model Evaluation Analysis/
â”‚   â””â”€â”€ Test Case Output Snapshots/
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ static/                     # CSS, favicon, static assets
    â”œâ”€â”€ templates/                  # HTML files (index.html)
    â”œâ”€â”€ app.py                      # Flask web application
    â”œâ”€â”€ feature_extraction.py       # Feature extraction logic
    â”œâ”€â”€ model_training.py           # Model training script
    â”œâ”€â”€ rf_model.pkl                # Trained ML model
    â”œâ”€â”€ convert_arff_to_csv.py      # ARFF â†’ CSV converter
    â”œâ”€â”€ Training Dataset.arff       # Original dataset
    â”œâ”€â”€ X_train.csv / X_test.csv    # Processed training/test data
    â””â”€â”€ requirements.txt            # Dependencies
```

---

## âš™ï¸ Tech Stack

| Category | Technologies |
|-----------|--------------|
| **Frontend** | HTML5, CSS3, JavaScript |
| **Backend** | Python (Flask Framework) |
| **Machine Learning** | scikit-learn, pandas, numpy |
| **Feature Processing** | tldextract, BeautifulSoup, requests, whois |
| **Model** | Random Forest Classifier |
| **Version Control** | Git & GitHub |
| **IDE** | PyCharm |

---

## ğŸ§  Dataset & Model

- **Dataset:** *Training Dataset.arff* (converted to CSV using `convert_arff_to_csv.py`)  
- **Features:** 30 extracted features (e.g., `SSLfinal_State`, `having_Sub_Domain`, `age_of_domain`, etc.)  
- **Algorithm:** Random Forest Classifier  
- **Goal:** Predict whether a given website is **phishing (0)** or **legitimate (1)**  

---

## ğŸ–¥ï¸ Running the Project Locally

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/phishing-website-detection.git
cd phishing-website-detection/src
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate     # For Windows
# OR
source venv/bin/activate  # For Mac/Linux
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Application
```bash
python app.py
```

### 5ï¸âƒ£ Visit in Browser
Open [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸŒ Deployment

### ğŸ”¸ On GitHub Pages
(For static version only â€” UI preview)
- Move your `index.html` & `style.css` to `/docs`
- Enable GitHub Pages in repo settings â†’ `/docs` branch.

---

## ğŸ“Š Example Output

| Input URL | Model Prediction | Explanation |
|------------|------------------|--------------|
| `http://secure-login-bank-update.com` | âš ï¸ Phishing Website Detected | Missing SSL, suspicious keywords, short domain age |
| `https://www.google.com` | âœ… Legitimate Website | Proper SSL, long-term domain, indexed by Google |

---

## ğŸ¤ Collaborators

| Name | Role |
|------|------|
| **Nabeel UrRehman** | Developer |
| **Syed Saad Ali** | Co-Developer |

---

## ğŸ“¦ Requirements

```text
Flask
pandas
numpy
scikit-learn
tldextract
requests
beautifulsoup4
python-whois
gunicorn
```

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€” youâ€™re free to use and modify it for educational or research purposes.

---

## ğŸ’¡ Future Enhancements

- ğŸ” Integrate live URL safety APIs (Google Safe Browsing, VirusTotal)
- ğŸ§  Include NLP-based feature extraction from webpage content
- ğŸ“Š Deploy dashboard for analytics of phishing trends
- â˜ï¸ Cloud hosting and API integration for real-time detection

---

## ğŸ Acknowledgement

This project is developed as part of an academic research work on  
We sincerely extend our gratitude to all those who guided and supported us throughout the development of this project.
Our heartfelt thanks go to our faculty mentors and academic supervisors for their valuable insights, continuous encouragement, and expert feedback that shaped this research into a successful outcome.

We would also like to acknowledge the contributions of cybersecurity communities and open-source developers, whose collective efforts and tools inspired and empowered this work.

Finally, we thank our family, friends, and collaborators for their constant motivation and unwavering belief in our vision.

**â€œTrue innovation comes when passion meets purpose â€” and teamwork turns ideas into impact.â€**
Inspired by real-world phishing defense mechanisms and modern web security standards.

---
## âš  Disclaimer
This tool is intended for *educational and research purposes only*.  
Predictions may not always be *100% accurate*.  
Use caution and verify suspicious websites manually.
---
> ğŸ’¬ â€œDetecting phishing isnâ€™t just about blocking fake sites â€” itâ€™s about building smarter, safer web experiences.â€
